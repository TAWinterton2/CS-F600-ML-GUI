{% extends 'base.html' %}

{% block head %}
    <title>Multi-Form Test</title>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/Chart.js/2.9.4/Chart.js"></script>

{% endblock %}


{% block body %}
    <div class="main">
        <div class="steps">
            <form id="regForm" action="">
                <div style="text-align:left; margin-top:20px;">
                    <span class="step"></span>
                    <span class="step"></span>
                    <span class="step"></span>
                    <span class="step"></span>
                </div>

                <h1 class="ML">Linear Regression</h1>
                
                <!-- Div for Uploading Dataset-->
                <div class="tab"><h2>Step 1: Uploading Dataset</h2>
                    <p>We would put instructions here to describe what type of dataset to use and what file type is accepted.</p>
                    <p>Below is a link that downloads a dummy CSV file that the user can use for testing</p>
                    <p><a href="">https://cdn.wsform.com/wp-content/uploads/2020/06/probability.csv.</a></p>
                    <p>Otherwise, the user can upload a .csv/.zip file.</p>
                    <input type="file" name="file" accept=".csv"> 
                    <p style="color:crimson">Here will be a notification that will appear when the file has been accepted or if an error occurred.</p>
                </div>

                <!-- Div for Scaling the Data Set-->
                <div class="tab"><h2>Step 2: Scaling the Dataset</h2>
                    <p>This section would explain what we mean by scaling the dataset, as well as what each option (if applicable)
                        means. The user will select an option (with standardize being the default) and then continue to the next step.
                    </p>
                    <select name="Scaling Type" id="scale">
                        <option value="Standardize">Standardize</option>
                        <option value="Normalize">Normalize</option>
                    </select>
                </div>

                <!-- Div for Setting Testing and Traning Sets-->
                <div class="tab"><h2>Step 3: Training and Testing</h2>
                    <p>We would explain what the testing + training datasets mean, the ideal split for this.</p>
                    <p><label for="training">Training:</label>
                    <input type="text" id="training" name="training "placeholder="80" oninput="this.className = ''"></p>
                    <p><label for="training">Testing:</label>
                    <input type="text" id="testing" name="testing" placeholder="20" oninput="this.className = ''"></p>
                    <p style="color:red">If the user inputs values that do not make sense (testing > training, testing+training>100),
                    an error will output here explaining what went wrong.</p>
                </div>


                <!-- Div for Changing all Hyperparameters-->
                <!-- Sorry if this div becomes super long :( 
                                            -Travis         -->
                <div class="tab"><h2>Step 4: Initialize the Model</h2>
                    <p>
                        List of all Hyperparameters associated with ML model are listed here 
                        <br>
                        <br>

                        Users can adjust any of these as they wish <br>
                        We will leave default values for all options and make a notice to the user that it is <br>
                        reccomended that they do not mess with any of these values at first untill they are <br>
                        comfertable with how the ML process works

                        <br>
                        <br>
                        each of these parameters will also be accompanyed by a description of what they do.
                        <br>  
                        <br>
                        <br>


                    </p>

                    <p>
                        <!-- 
                            Parameter: Loss Strength:

                            Dependent: No

                            The loss function to be used. 
                            The possible values are ‘squared_error’, ‘huber’, ‘epsilon_insensitive’, or ‘squared_epsilon_insensitive’

                            The ‘squared_error’ refers to the ordinary least squares fit. 
                            ‘huber’ modifies ‘squared_error’ to focus less on getting outliers correct by switching from squared to linear loss past a distance of epsilon. 
                            ‘epsilon_insensitive’ ignores errors less than epsilon and is linear past that; this is the loss function used in SVR. 
                            ‘squared_epsilon_insensitive’ is the same but becomes squared loss past a tolerance of epsilon.
                        -->
                        Loss Strength:
                        <select name = "loss Strength" id="Hyperparameters">
                            <option value="square_error">Squared Error</option>
                            <option value="epsilon_insensitive">Epsilon Insensitive</option>
                            <option value="squared_epsilion_insensitive">Squared Epsilon Insensitive</option>
                        </select>

                        &ensp;
                        
                        <!--
                            Parameter Penalty:

                            Dependent: No

                            The penalty (aka regularization term) to be used. Defaults to ‘l2’ which is the standard regularizer for linear SVM models. 
                            ‘l1’ and ‘elasticnet’ might bring sparsity to the model (feature selection) not achievable with ‘l2’. 

                            No penalty is added when set to None.
                        -->
                        Penalty:
                        <select name="penalty" id="Hyperparameters">
                            <option value="l2">l2</option>
                            <option value="l1">l1</option>
                            <option value="elasticent">Elasticent</option>
                            <option value="none">None</option>
                        </select>

                    </p>

                    <p>
                        <!--
                            Parameter: Alpha

                            Dependent: No

                            Constant that multiplies the regularization term. 
                            The higher the value, the stronger the regularization. 
                            Also used to compute the learning rate when set to learning_rate is set to ‘optimal’.

                        -->
                        <label for="alpha">Alpha:</label>
                        <input type="text" id="Hyperparameters" name="alpha" placeholder="0.0001" oninput="this.className = ' '">
                       
                        <!--
                            Parameter l1_ratio:

                            Dependent: "Penalty"

                            The Elastic Net mixing parameter, with 0 <= l1_ratio <= 1. 
                            l1_ratio=0 corresponds to L2 penalty, l1_ratio=1 to L1. 
                            Only used if penalty is ‘elasticnet’.
                        -->
                        <label for="l1_ratio">l1 Ratio:</label>
                        <input type="text" id="Hyperparameters" name="l1_ratio" placeholder="0.15" oninput="this.className =''">
    
                    </p>

                    <p>
                        <!--
                            Parameter: Fit Intercept:

                            Dependent: No

                            Whether the intercept should be estimated or not. If False, the data is assumed to be already centered.
                        -->
                        Fit Intercept:
                        <input type="radio" id="Hyperparameters" name="fit_int_true" value="fit_int_true" checked>
                        <label for="true">True</label>
                        <input type="radio" id="Hyperparameters" name="fit_int_false" value="fit_int_false">
                        <label for="false">False</label><br>
                    </p>

                    <p>
                        <!--
                            Parameter: Max Iteration:
                            
                            Dependent: No

                            The maximum number of passes over the training data (aka epochs). 
                            It only impacts the behavior in the fit method, and not the partial_fit method.
                        -->
                        <label for="max_iter">Max Iteration:</label>   
                        <input type="text" id="Hyperparameters" name="max_iter" placeholder="1000" oninput="this.className = ''">   
                    </p>

                    <p>
                        <!-- 
                            Parameter: Shuffle

                            Dependent: No

                            Whether or not the training data should be shuffled after each epoch.
                        -->
                        Shuffle:
                        <input type="radio" id="Hyperparameters" name="shuffle_true" value="true" checked>
                        <label for="true">True</label>
                        <input type="radio" id="Hyperparameters" name="shuffle_false" value="false">
                        <lable for="false">False</lable>
                    </p>



                    <p>
                        <!--
                            Parameter: Verbose

                            Dependent: No

                            The verbosity level.
                        -->
                        <label for="verbose">Verbose:</label>
                        <input type="text" id="Hyperparameters" name="verbose" placeholder="0" oninput="this.className=''">
                    </p>

                    <p>
                        <!--
                            Parameter: Epsilon

                            Dependent: "Loss"

                            Epsilon in the epsilon-insensitive loss functions; only if loss is ‘huber’, ‘epsilon_insensitive’, or ‘squared_epsilon_insensitive’. 
                            For ‘huber’, determines the threshold at which it becomes less important to get the prediction exactly right. 
                            For epsilon-insensitive, any differences between the current prediction and the correct label are ignored if they are less than this threshold.
                        -->
                        <label for="epsilon">Epsilon</label>
                        <input type="text" id="Hyperparameters" name="epsilon" placeholder="0.1" oninput="this.className=''">
                    </p>

                    <p>
                        <!--
                            Parameter: Randome State

                            Dependent: "Shuffle == True"

                            Used for shuffling the data, when shuffle is set to True. 
                            Pass an int for reproducible output across multiple function calls.
                        -->
                        <label for="rand_state">Random State</label>
                        <input type="text" id="Hyperparameters" name="rand_state" placeholder="0" oninput="this.className=''" disabled>

                    </p>

                    <p>
                        <!--
                            Parameter: Learning Rate:

                            Dependent: None

                            The learning rate schedule:

                                ‘constant’: eta = eta0

                                ‘optimal’: eta = 1.0 / (alpha * (t + t0)) where t0 is chosen by a heuristic proposed by Leon Bottou.

                                ‘invscaling’: eta = eta0 / pow(t, power_t)

                                ‘adaptive’: eta = eta0, as long as the training keeps decreasing. 
                                Each time n_iter_no_change consecutive epochs fail to decrease the training loss by 
                                tol or fail to increase validation score by tol if early_stopping is True, the current learning rate is divided by 5.
                        -->
                        Learning Rate:
                        <select name="learning_rate" id="Hyperparameters">
                            <option value="invscaling">Invscaling</option>
                            <option value="constant">Constant</option>
                            <option value="optimal">Optimal</option>
                            <option value="adaptive">Adaptive</option>
                        </select>
                    </p>

                    <p>
                        <!--
                            Parameter: eta0

                            Dependent: None

                            The initial learning rate for the ‘constant’, ‘invscaling’ or ‘adaptive’ schedules. The default value is 0.01.
                        -->
                        <label for="eta0">eta0</label>
                        <input type="text" id="Hyperparameters" name="epsilon" placeholder="0.01" oninput="this.className=''">

                    </p>

                    <p>
                        <!--
                            Parameter: power_t

                            Dependent: None

                            The exponent for inverse scaling learning rate.
                        -->
                        <label for="power_t">Power_T</label>
                        <input type="text" id="Hyperparameters" name="power_t" placeholder="0.25" oninput="this.className=''">

                    </p>

                    <p>
                        <!--
                            Parameter: Early Stopping

                            Depedent: None

                            Whether to use early stopping to terminate training when validation score is not improving. 
                            If set to True, it will automatically set aside a fraction of training data as validation and 
                            terminate training when validation score returned by the score method is not improving by at least tol for n_iter_no_change consecutive epochs.
                        -->
                        Early Stopping:
                        <input type="radio" id="Hyperparameters" name="Erl_stop_true" value="true">
                        <label for="true">True</label>
                        <input type="radio" id="Hyperparameters" name="Erl_stop_false" value="false" checked>
                        <label for="false">False</label>
                    </p>
                    
                    <p>
                        <!--
                            Parameter: Validation_fraction

                            Dependent: "Early Stopping == True"

                            The proportion of training data to set aside as validation set for early stopping. 
                            Must be between 0 and 1. Only used if early_stopping is True.

                        -->
                        <label for="validation_fraction">Validation Fraction</label>
                        <input type="text" id="Hyperparameters" name="validation_fraction" placeholder="0.1" oninput="this.className=''">
                    </p>

                    <p>
                        <!--
                            Parameter: tol

                            Dependent: Minor "Early Stopping" || "n_iter_no_change"

                            The stopping criterion. If it is not None, training will stop when (loss > best_loss - tol) for n_iter_no_change consecutive epochs. 
                            Convergence is checked against the training loss or the validation loss depending on the early_stopping parameter.


                        -->

                        <label for ="tol">Tol</label>
                        <input type="text" id="Hyperparameters" name="tol" placeholder="0.001" oninput="this.className=''">
                    </p>

                    <p>
                        <!--
                            Parameter: n_iter_no_change

                            Dependent: Minor "Early Stopping"

                            Number of iterations with no improvement to wait before stopping fitting. 
                            Convergence is checked against the training loss or the validation loss depending on the early_stopping parameter.


                        -->
                        <label for="n_iter_no_change"> # of Iterations (no change) </label>
                        <input type="text" id="Hyperparameters" name="n_iter_no_change" placeholder="5" oninput="this.className=''">

                    </p>

                    <p>
                        <!--
                            Parameter: Warm Start

                            Dependent: None

                            When set to True, reuse the solution of the previous call to fit as initialization, otherwise, just erase the previous solution.

                            Repeatedly calling fit or partial_fit when warm_start is True can result in a different solution than when calling fit a 
                            single time because of the way the data is shuffled. 

                            If a dynamic learning rate is used, the learning rate is adapted depending on the number of samples already seen. 
                            Calling fit resets this counter, while partial_fit will result in increasing the existing counter.
                        -->
                        Warm Start:
                        <input type="radio" id="Hyperparameters" name="warm_start_true" value="true">
                        <label for="true">True</label>
                        <input type="radio" id="Hyperparameters" name="warm_start_false" value="false" checked>
                        <label for="false">false</label>
                    </p>

                    <p>
                        <!--
                            Parameter: Average

                            Dependent: None

                            When set to True, computes the averaged SGD weights across all updates and stores the result in the coef_ attribute. 
                            If set to an int greater than 1, averaging will begin once the total number of samples seen reaches average. 

                            So average=10 will begin averaging after seeing 10 samples.
                        -->
                        Average:
                        <input type="radio" id="Hyperparameters" name="average_true" value="true">
                        <label for="true">True</label>
                        <input type="radio" id="Hyperparameters" name="average_false" value="false" checked>
                        <label for="false">false</label>
                    </p>



                </div>
                
                <!-- Div for Running the Model-->
                <div class="tab"><h2>Step 5: Run</h2>
                    <p>If possible, we would review all the settings the user has inputted so the user 
                        can view everything before running. When the user presses the run button, the model
                        will run with the provided settings and either output an error message OR proceed to evaluation.</p>
                    <button type="button" id="run">Run!</button>

                </div>

                <!-- Next and Previous Buttons for Multi-page form-->
                <div style="overflow:auto;">
                    <div style="float:right;">
                    <button type="button" id="prevStp" onclick="nextPrev(-1)">Previous</button>
                    <button type="button" id="nextStp" onclick="nextPrev(1)">Next</button>
                    </div>
                </div>

            </form>
            <script type="text/javascript" src="{{url_for('static', filename='ml_form_script.js')}}"></script>
        </div>


        <!-- Div for Output Display on Right Hand Side of Webpage-->
        <div class="display">
            <div class="output">
                <h1>Output</h1>
                <p>Here would be any visualizations from the program.</p>
                <p>Usually, when the user finishes a step it will output some sort of visualization.</p>
                <ul>Step 2: visualizes the whole dataset</ul>
                <ul>Step 3: visualize the testing and training data-split</ul>
                <ul>Step 5: Running the model outputs the error processing / evaluation graphs.</ul>
                <canvas id="myChart" style="width:100%;max-width:300px;background-color: antiquewhite;align-content: center;"></canvas>
                <script>
                    const xyValues = [
                    {x:50, y:7},
                    {x:60, y:8},
                    {x:70, y:8},
                    {x:80, y:9},
                    {x:90, y:9},
                    {x:100, y:9},
                    {x:110, y:10},
                    {x:120, y:11},
                    {x:130, y:14},
                    {x:140, y:14},
                    {x:150, y:15}
                    ];

                    
                new Chart("myChart", {
                type: "scatter",
                data: {
                    datasets: [{
                    pointRadius: 4,
                    pointBackgroundColor: "rgb(0,0,255)",
                    data: xyValues
                    }]
                },
                options: {
                    legend: {display: false},
                    scales: {
                    xAxes: [{ticks: {min: 40, max:160}}],
                    yAxes: [{ticks: {min: 6, max:16}}],
                    }
                }
                });
                </script>
            </div>
        </div>
    </div>
{% endblock %}